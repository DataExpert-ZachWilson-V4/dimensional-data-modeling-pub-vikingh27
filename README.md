# Dimensional Data Modeling

## Submission Guidelines

To ensure smooth processing of your submissions through GitHub Classroom automation, we cannot accommodate individual requests for changes. Therefore, please read all instructions carefully.

1. **Sync fork:** Ensure your fork is up-to-date with the upstream repository. You can do this through the GitHub UI or by running the following commands in your local forked repository:

    ```bash
    git pull upstream main --rebase
    git push origin <main/your_homework_repo> -f
    ```

3. **Open a PR in THIS repository to submit your work:**
    - Open a Pull Request (PR) to merge changes from your `main` or custom `homework` branch in your forked repository into the main branch in the upstream repository, i.e., the repository your fork was created from.
    - Ensure your PR is opened correctly to trigger the GitHub workflow. Submitting to the wrong branch or repository will cause the GitHub action to fail.
    - See the [Steps to open a PR](#steps-to-open-a-pr) section below if you need help with this.

5. **Complete assignment prompts:** Write your SQL in the query file corresponding to the prompt number in the **`submission`** folder. Do not change or rename these files!
    >
    > :warning: The `_app` folder, `Dockerfile`, and `.github` folder are crucial for automated tests and feedback.
Do not modify these files/folders. Focus only on the files within the submission folder.
    >

6. **Lint your SQL code for readability.** Ensure your code is clean and easy to follow.

7. **Add comments to your queries.** Use the **`--`** syntax to explain each step and help the reviewer understand your thought process. 

A link to your PR will be automatically shared with our TA team. They will review and grade submissions after the homework deadline.

### Steps to open a PR
  1. Go to the upstream [**`dimensional-data-modeling-pub`**](https://github.com/DataExpert-ZachWilson-V4/dimensional-data-modeling-pub) repository
  2. Click the [**Pull Requests**](https://github.com/DataExpert-ZachWilson-V4/dimensional-data-modeling-pub/pulls) tab.
  3. Click the **"New pull request"** button on the top-right. This will take you to the [**"Compare changes"**](https://github.com/DataExpert-ZachWilson-V4/dimensional-data-modeling-pub/compare) page.
  4. Click the **"compare across forks"** link in the text.
  5. Leave the base repository as is. For the **"head repository"**, select your forked repository and then the name of the branch you want to compare from your forked repo:
     - <img src="compare_changes_screenshot.png" alt="screenshot of compare changes page in GitHub" width="600">
  6. Click the **"Create pull request"** button to open the PR

**:warning: :exclamation: IMPORTANT CONSIDERATIONS & REMINDERS :exclamation: :warning:**
  - Do not close or merge your PR, as this will affect the codebase for others and make it difficult for TAs to find your submission.
  - You can revise and push changes to the PR before the deadline, but avoid making changes after the deadline, as they will not be reviewed and may cause confusion.
  - Some assignments include tests or feedback generated by GitHub Actions, which you can use to refine your solutions before the deadline.
  - Enhance your review by adding comments under 'Files changed' to summarize or highlight key parts of your code. If you've already added comments within your code, you can reiterate or summarize those comments here.

### Grading
  - Grades are pass or fail, used solely for certification.
  - Final grades will be submitted by a TA **after the deadline**.
  - An approved PR means a Pass grade. If changes are requested, the grade will be marked as Fail.
  - Reviewers may provide comments or suggestions with requested changes. These are optional and intended for your benefit. Any changes you make in response will not be re-reviewed.

Assignment
==================

## Dataset Overview

This assignment involves working with the **`actor_films`** dataset. Your task is to construct a series of SQL queries and table definitions that will allow us to model the **`actor_films`** dataset in a way that facilitates efficient analysis. This involves creating new tables, defining data types, and writing queries to populate these tables with data from the **`actor_films`** dataset.

The `actor_films` dataset contains the following fields:

- `actor`: The name of the actor.
- `actor_id`: A unique identifier for each actor.
- `film`: The name of the film.
- `year`: The year the film was released.
- `votes`: The number of votes the film received.
- `rating`: The rating of the film.
- `film_id`: A unique identifier for each film.

The primary key for this dataset is (`actor_id`, `film_id`).

## Assignment Tasks

### Actors Table DDL (query_1)

Write a DDL query to create an `actors` table with the following fields:

- `actor`: Actor name
- `actor_id`: Actor's ID
- `films`: An array of `struct` with the following fields:
  - `film`: The name of the film.
  - `votes`: The number of votes the film received.
  - `rating`: The rating of the film.
  - `film_id`: A unique identifier for each film.
- `quality_class`: A categorical bucketing of the average rating of the movies for this actor in their most recent year:
  - `star`: Average rating > 8.
  - `good`: Average rating > 7 and ≤ 8.
  - `average`: Average rating > 6 and ≤ 7.
  - `bad`: Average rating ≤ 6.
- `is_active`: A BOOLEAN field that indicates whether an actor is currently active in the film industry (i.e., making films this year).
- `current_year`: The year this row represents for the actor

### Cumulative Table Computation Query (query_2)

Write a query that populates the `actors` table one year at a time.

### Actors History SCD Table DDL (query_3)

Write a DDL statement to create an `actors_history_scd` table that tracks the following fields for each actor in the `actors` table:

- `quality_class`
- `is_active`
- `start_date`
- `end_date`

Note that this table should be appropriately modeled as a Type 2 Slowly Changing Dimension Table (`start_date` and `end_date`).

### Actors History SCD Table Batch Backfill Query (query_4)

Write a "backfill" query that can populate the entire `actors_history_scd` table in a single query.

### Actors History SCD Table Incremental Backfill Query (query_5)

Write an "incremental" query that can populate a single year's worth of the `actors_history_scd` table by combining the previous year's SCD data with the new incoming data from the `actors` table for this year.
